#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æŠ–éŸ³ä¸‹è½½å™¨ - ç»Ÿä¸€å¢å¼ºç‰ˆ
æ”¯æŒè§†é¢‘ã€å›¾æ–‡ã€ç”¨æˆ·ä¸»é¡µã€åˆé›†ç­‰å¤šç§å†…å®¹çš„æ‰¹é‡ä¸‹è½½
"""

import asyncio
import json
import logging
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from urllib.parse import urlparse
import argparse
import yaml

# ç¬¬ä¸‰æ–¹åº“
try:
    import aiohttp
    import requests
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn
    from rich.table import Table
    from rich.panel import Panel
    from rich.live import Live
    from rich import print as rprint
except ImportError as e:
    print(f"è¯·å®‰è£…å¿…è¦çš„ä¾èµ–: pip install aiohttp requests rich pyyaml")
    sys.exit(1)

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from apiproxy.douyin import douyin_headers
from apiproxy.douyin.urls import Urls
from apiproxy.douyin.result import Result
from apiproxy.common.utils import Utils
from apiproxy.douyin.auth.cookie_manager import AutoCookieManager
from apiproxy.douyin.auth.signature_generator import get_x_bogus, get_a_bogus
from apiproxy.douyin.database import DataBase
from apiproxy.douyin.core.download_logger import DownloadLogger

# é…ç½®æ—¥å¿— - åªè®°å½•åˆ°æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('downloader.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# æ§åˆ¶å°æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºWARNINGï¼Œå‡å°‘å¹²æ‰°
for handler in logging.root.handlers:
    if isinstance(handler, logging.StreamHandler) and not isinstance(handler, logging.FileHandler):
        handler.setLevel(logging.WARNING)

# Rich console
console = Console()


class ContentType:
    """å†…å®¹ç±»å‹æšä¸¾"""
    VIDEO = "video"
    IMAGE = "image" 
    USER = "user"
    MIX = "mix"
    MUSIC = "music"
    LIVE = "live"


class DownloadStats:
    """ä¸‹è½½ç»Ÿè®¡"""
    def __init__(self):
        self.total = 0
        self.success = 0
        self.failed = 0
        self.skipped = 0
        self.start_time = time.time()
    
    @property
    def success_rate(self):
        return (self.success / self.total * 100) if self.total > 0 else 0
    
    @property
    def elapsed_time(self):
        return time.time() - self.start_time
    
    def to_dict(self):
        return {
            'total': self.total,
            'success': self.success,
            'failed': self.failed,
            'skipped': self.skipped,
            'success_rate': f"{self.success_rate:.1f}%",
            'elapsed_time': f"{self.elapsed_time:.1f}s"
        }


class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    def __init__(self, max_per_second: float = 2):
        self.max_per_second = max_per_second
        self.min_interval = 1.0 / max_per_second
        self.last_request = 0
    
    async def acquire(self):
        """è·å–è®¸å¯"""
        current = time.time()
        time_since_last = current - self.last_request
        if time_since_last < self.min_interval:
            await asyncio.sleep(self.min_interval - time_since_last)
        self.last_request = time.time()


class RetryManager:
    """é‡è¯•ç®¡ç†å™¨"""
    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
        self.retry_delays = [1, 2, 5]  # é‡è¯•å»¶è¿Ÿ
    
    async def execute_with_retry(self, func, *args, **kwargs):
        """æ‰§è¡Œå‡½æ•°å¹¶è‡ªåŠ¨é‡è¯•"""
        last_error = None
        for attempt in range(self.max_retries):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                last_error = e
                if attempt < self.max_retries - 1:
                    delay = self.retry_delays[min(attempt, len(self.retry_delays) - 1)]
                    logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}, {delay}ç§’åé‡è¯•...")
                    await asyncio.sleep(delay)
        raise last_error


class UnifiedDownloader:
    """ç»Ÿä¸€ä¸‹è½½å™¨"""

    def __init__(self, config_path: str = "config_downloader.yml"):
        self.config = self._load_config(config_path)
        self.urls_helper = Urls()
        self.result_helper = Result()
        self.utils = Utils()

        # ç»„ä»¶åˆå§‹åŒ–
        self.stats = DownloadStats()
        self.rate_limiter = RateLimiter(max_per_second=2)
        self.retry_manager = RetryManager(max_retries=self.config.get('retry_times', 3))

        # msTokenå’Œç­¾åç›¸å…³
        self.mstoken = self._generate_mstoken()
        self.device_id = self._generate_device_id()
        
        # Cookieä¸è¯·æ±‚å¤´ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œæ”¯æŒè‡ªåŠ¨è·å–ï¼‰
        self.cookies = self.config.get('cookies') if 'cookies' in self.config else self.config.get('cookie')

        # æ£€æµ‹Cookieé…ç½®ç±»å‹
        self.auto_cookie = bool(self.config.get('auto_cookie')) or (isinstance(self.config.get('cookie'), str) and self.config.get('cookie') == 'auto') or (isinstance(self.config.get('cookies'), str) and self.config.get('cookies') == 'auto')

        # æ£€æµ‹browser-cookiesæ¨¡å¼ï¼ˆyt-dlpæ–¹å¼ï¼‰
        self.browser_cookie = None
        if isinstance(self.cookies, str) and self.cookies.startswith('browser:'):
            # æ ¼å¼: browser:chrome æˆ– browser:edge ç­‰
            self.browser_cookie = self.cookies.split(':', 1)[1] if ':' in self.cookies else 'chrome'
            self.cookies = None  # ç¨åä»æµè§ˆå™¨è·å–

        self.headers = {**douyin_headers}
        # é¿å…æœåŠ¡ç«¯ä½¿ç”¨brotliå¯¼è‡´aiohttpæ— æ³•è§£å‹ï¼ˆæœªå®‰è£…brotliåº“æ—¶ä¼šå‡ºç°ç©ºå“åº”ï¼‰
        self.headers['accept-encoding'] = 'gzip, deflate'
        # å¢é‡ä¸‹è½½ä¸æ•°æ®åº“
        self.increase_cfg: Dict[str, Any] = self.config.get('increase', {}) or {}
        self.enable_database: bool = bool(self.config.get('database', True))
        self.db: Optional[DataBase] = DataBase() if self.enable_database else None
        
        # ä¿å­˜è·¯å¾„
        self.save_path = Path(self.config.get('path', './Downloaded'))
        self.save_path.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–ä¸‹è½½æ—¥å¿—è®°å½•å™¨
        self.download_logger = DownloadLogger(str(self.save_path))
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            # é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶è¿”å›ç©ºé…ç½®
            print(f"è­¦å‘Š: é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {}

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        # ç®€åŒ–é…ç½®å…¼å®¹ï¼šlinks/link, output_dir/path, cookie/cookies
        if 'links' in config and 'link' not in config:
            config['link'] = config['links']
        if 'output_dir' in config and 'path' not in config:
            config['path'] = config['output_dir']
        if 'cookie' in config and 'cookies' not in config:
            config['cookies'] = config['cookie']
        if isinstance(config.get('cookies'), str) and config.get('cookies') == 'auto':
            config['auto_cookie'] = True

        # å…è®¸æ—  linkï¼ˆé€šè¿‡å‘½ä»¤è¡Œä¼ å…¥ï¼‰
        # å¦‚æœä¸¤è€…éƒ½æ²¡æœ‰ï¼Œåç»­ä¼šåœ¨è¿è¡Œæ—¶æç¤º

        return config

    def _generate_mstoken(self) -> str:
        """ç”ŸæˆmsToken"""
        import random
        import string

        # msTokenæ ¼å¼é€šå¸¸æ˜¯ä¸€ä¸ªéšæœºå­—ç¬¦ä¸²ï¼Œé•¿åº¦çº¦107ä¸ªå­—ç¬¦
        # å­—ç¬¦é›†åŒ…å«å¤§å°å†™å­—æ¯ã€æ•°å­—å’Œç‰¹æ®Šå­—ç¬¦
        charset = string.ascii_letters + string.digits + '-_='

        # ç”ŸæˆåŸºç¡€éšæœºå­—ç¬¦ä¸²
        base_length = random.randint(100, 110)
        mstoken = ''.join(random.choice(charset) for _ in range(base_length))

        logger.info(f"ç”ŸæˆmsToken: {mstoken[:20]}...")
        return mstoken

    def _generate_device_id(self) -> str:
        """ç”Ÿæˆè®¾å¤‡ID"""
        import random

        # è®¾å¤‡IDé€šå¸¸æ˜¯19ä½æ•°å­—
        device_id = ''.join([str(random.randint(0, 9)) for _ in range(19)])
        logger.info(f"ç”Ÿæˆè®¾å¤‡ID: {device_id}")
        return device_id
    
    def _build_cookie_string(self) -> str:
        """æ„å»ºCookieå­—ç¬¦ä¸²"""
        if isinstance(self.cookies, str):
            return self.cookies
        elif isinstance(self.cookies, dict):
            return '; '.join([f'{k}={v}' for k, v in self.cookies.items()])
        elif isinstance(self.cookies, list):
            # æ”¯æŒæ¥è‡ªAutoCookieManagerçš„cookiesåˆ—è¡¨
            try:
                kv = {c.get('name'): c.get('value') for c in self.cookies if c.get('name') and c.get('value')}
                return '; '.join([f'{k}={v}' for k, v in kv.items()])
            except Exception:
                return ''
        return ''

    async def _initialize_cookies_and_headers(self):
        """åˆå§‹åŒ–Cookieä¸è¯·æ±‚å¤´ï¼ˆæ”¯æŒå¤šç§è·å–æ–¹å¼ï¼‰"""

        # æ–¹å¼1: browser:chrome æ¨¡å¼ï¼ˆyt-dlpæ–¹å¼ï¼‰
        if self.browser_cookie:
            try:
                console.print(f"[cyan]ğŸ” ä»{self.browser_cookie}æµè§ˆå™¨æå–Cookieï¼ˆyt-dlpæ–¹å¼ï¼‰...[/cyan]")
                from apiproxy.douyin.auth.browser_cookies import get_browser_cookies

                # ç›´æ¥ä»æµè§ˆå™¨æ•°æ®åº“æå–Cookie
                browser_cookies = get_browser_cookies(self.browser_cookie, '.douyin.com')

                if browser_cookies:
                    self.cookies = browser_cookies
                    cookie_str = self._build_cookie_string()
                    if cookie_str:
                        self.headers['Cookie'] = cookie_str
                        from apiproxy.douyin import douyin_headers
                        douyin_headers['Cookie'] = cookie_str

                        # æ˜¾ç¤ºæå–åˆ°çš„å…³é”®Cookie
                        if 'msToken' in browser_cookies:
                            console.print(f"[green]âœ… æå–åˆ°msToken: {browser_cookies['msToken'][:30]}...[/green]")
                        if 'ttwid' in browser_cookies:
                            console.print(f"[green]âœ… æå–åˆ°ttwid: {browser_cookies['ttwid'][:30]}...[/green]")
                        if 'sessionid' in browser_cookies:
                            console.print(f"[green]âœ… æå–åˆ°sessionidï¼ˆå·²ç™»å½•ï¼‰[/green]")

                        console.print(f"[green]âœ… ä»{self.browser_cookie}æˆåŠŸæå–{len(browser_cookies)}ä¸ªCookie[/green]")
                        return

            except Exception as e:
                logger.error(f"ä»æµè§ˆå™¨æå–Cookieå¤±è´¥: {e}")
                console.print(f"[red]âŒ ä»{self.browser_cookie}æå–Cookieå¤±è´¥: {e}[/red]")

        # æ–¹å¼2: é…ç½®ä¸ºå­—ç¬¦ä¸² 'auto'
        if isinstance(self.cookies, str) and self.cookies.strip().lower() == 'auto':
            self.cookies = None

        # æ–¹å¼3: å·²æ˜¾å¼æä¾›cookies
        cookie_str = self._build_cookie_string()
        if cookie_str:
            self.headers['Cookie'] = cookie_str
            from apiproxy.douyin import douyin_headers
            douyin_headers['Cookie'] = cookie_str
            return

        # æ–¹å¼4: è‡ªåŠ¨è·å–Cookieï¼ˆPlaywrightæ–¹å¼ï¼‰
        if self.auto_cookie:
            try:
                console.print("[cyan]ğŸ” æ­£åœ¨è‡ªåŠ¨è·å–Cookieï¼ˆPlaywrightæ–¹å¼ï¼‰...[/cyan]")
                async with AutoCookieManager(cookie_file='cookies.pkl', headless=False) as cm:
                    cookies_list = await cm.get_cookies()
                    if cookies_list:
                        self.cookies = cookies_list
                        cookie_str = self._build_cookie_string()
                        if cookie_str:
                            self.headers['Cookie'] = cookie_str
                            from apiproxy.douyin import douyin_headers
                            douyin_headers['Cookie'] = cookie_str
                            console.print("[green]âœ… Cookieè·å–æˆåŠŸ[/green]")
                            return
                console.print("[yellow]âš ï¸ è‡ªåŠ¨è·å–Cookieå¤±è´¥æˆ–ä¸ºç©ºï¼Œç»§ç»­å°è¯•æ— Cookieæ¨¡å¼[/yellow]")
            except Exception as e:
                logger.warning(f"è‡ªåŠ¨è·å–Cookieå¤±è´¥: {e}")
                console.print("[yellow]âš ï¸ è‡ªåŠ¨è·å–Cookieå¤±è´¥ï¼Œç»§ç»­å°è¯•æ— Cookieæ¨¡å¼[/yellow]")

        # æœªèƒ½è·å–Cookieåˆ™ä¸è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤headers
    
    def detect_content_type(self, url: str) -> ContentType:
        """æ£€æµ‹URLå†…å®¹ç±»å‹"""
        if '/user/' in url:
            return ContentType.USER
        elif '/video/' in url or 'v.douyin.com' in url:
            return ContentType.VIDEO
        elif '/note/' in url:
            return ContentType.IMAGE
        elif '/collection/' in url or '/mix/' in url:
            return ContentType.MIX
        elif '/music/' in url:
            return ContentType.MUSIC
        elif 'live.douyin.com' in url:
            return ContentType.LIVE
        else:
            return ContentType.VIDEO  # é»˜è®¤å½“ä½œè§†é¢‘
    
    async def resolve_short_url(self, url: str) -> str:
        """è§£æçŸ­é“¾æ¥"""
        if 'v.douyin.com' in url:
            try:
                # ä½¿ç”¨æ›´å®Œæ•´çš„è¯·æ±‚å¤´æ¨¡æ‹Ÿæµè§ˆå™¨
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Cache-Control': 'no-cache',
                    'Pragma': 'no-cache',
                    'Sec-Ch-Ua': '"Chromium";v="122", "Not(A:Brand";v="24", "Google Chrome";v="122"',
                    'Sec-Ch-Ua-Mobile': '?0',
                    'Sec-Ch-Ua-Platform': '"macOS"',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none',
                    'Sec-Fetch-User': '?1',
                    'Upgrade-Insecure-Requests': '1'
                }

                # è·å–åˆæ¬¡é‡å®šå‘
                session = requests.Session()
                response = session.get(url, headers=headers, allow_redirects=False, timeout=10)

                # å¤„ç†é‡å®šå‘é“¾
                redirect_count = 0
                max_redirects = 5
                current_url = url

                while redirect_count < max_redirects:
                    if response.status_code in [301, 302, 303, 307, 308]:
                        location = response.headers.get('Location', '')
                        if location:
                            # å¤„ç†ç›¸å¯¹è·¯å¾„
                            if location.startswith('/'):
                                parsed = urlparse(current_url)
                                location = f"{parsed.scheme}://{parsed.netloc}{location}"
                            elif not location.startswith('http'):
                                parsed = urlparse(current_url)
                                location = f"{parsed.scheme}://{parsed.netloc}/{location}"

                            current_url = location
                            logger.debug(f"é‡å®šå‘ {redirect_count + 1}: {location}")

                            # æ£€æŸ¥æ˜¯å¦åŒ…å«è§†é¢‘ID
                            if '/video/' in location or '/note/' in location or 'modal_id=' in location:
                                logger.info(f"è§£æçŸ­é“¾æ¥æˆåŠŸ: {url} -> {location}")
                                return location

                            # ç»§ç»­è·Ÿéšé‡å®šå‘
                            response = session.get(location, headers=headers, allow_redirects=False, timeout=10)
                            redirect_count += 1
                        else:
                            break
                    else:
                        # éé‡å®šå‘çŠ¶æ€ï¼Œæ£€æŸ¥æœ€ç»ˆURL
                        if '/video/' in current_url or '/note/' in current_url:
                            logger.info(f"è§£æçŸ­é“¾æ¥æˆåŠŸ: {url} -> {current_url}")
                            return current_url
                        break

                # å¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ç›´æ¥è®¿é—®å¹¶è§£æå“åº”å†…å®¹
                response = session.get(url, headers=headers, allow_redirects=True, timeout=10)
                final_url = response.url

                # ä»å“åº”å†…å®¹ä¸­æå–è§†é¢‘ID
                if response.text:
                    import re
                    # å°è¯•ä»é¡µé¢ä¸­æå–è§†é¢‘ID
                    video_id_match = re.search(r'/video/(\d+)', response.text)
                    if video_id_match:
                        video_id = video_id_match.group(1)
                        video_url = f"https://www.douyin.com/video/{video_id}"
                        logger.info(f"ä»é¡µé¢å†…å®¹æå–è§†é¢‘ID: {url} -> {video_url}")
                        return video_url

                    # å°è¯•ä» meta æ ‡ç­¾ä¸­æå–
                    canonical_match = re.search(r'<link[^>]+rel=["\']canonical["\'][^>]+href=["\']([^"\']+)["\']', response.text)
                    if canonical_match:
                        canonical_url = canonical_match.group(1)
                        if '/video/' in canonical_url or '/note/' in canonical_url:
                            logger.info(f"ä» canonical æ ‡ç­¾æå–: {url} -> {canonical_url}")
                            return canonical_url

                # æœ€åçš„å¤‡ç”¨ï¼šå¦‚æœæœ€ç»ˆURLçœ‹èµ·æ¥æœ‰æ•ˆ
                if final_url and 'douyin.com' in final_url and final_url != 'https://www.douyin.com':
                    logger.info(f"è§£æçŸ­é“¾æ¥: {url} -> {final_url}")
                    return final_url

                logger.warning(f"è§£æçŸ­é“¾æ¥å¤±è´¥ï¼Œè¿”å›åŸå§‹URL: {url}")
                return url

            except Exception as e:
                logger.warning(f"è§£æçŸ­é“¾æ¥å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        return url
    
    def extract_id_from_url(self, url: str, content_type: ContentType = None) -> Optional[str]:
        """ä»URLæå–ID
        
        Args:
            url: è¦è§£æçš„URL
            content_type: å†…å®¹ç±»å‹ï¼ˆå¯é€‰ï¼Œç”¨äºæŒ‡å¯¼æå–ï¼‰
        """
        # å¦‚æœå·²çŸ¥æ˜¯ç”¨æˆ·é¡µé¢ï¼Œç›´æ¥æå–ç”¨æˆ·ID
        if content_type == ContentType.USER or '/user/' in url:
            user_patterns = [
                r'/user/([\w-]+)',
                r'sec_uid=([\w-]+)'
            ]
            
            for pattern in user_patterns:
                match = re.search(pattern, url)
                if match:
                    user_id = match.group(1)
                    logger.info(f"æå–åˆ°ç”¨æˆ·ID: {user_id}")
                    return user_id
        
        # è§†é¢‘IDæ¨¡å¼ï¼ˆä¼˜å…ˆï¼‰
        video_patterns = [
            r'/video/(\d+)',
            r'/note/(\d+)',
            r'modal_id=(\d+)',
            r'aweme_id=(\d+)',
            r'item_id=(\d+)'
        ]
        
        for pattern in video_patterns:
            match = re.search(pattern, url)
            if match:
                video_id = match.group(1)
                logger.info(f"æå–åˆ°è§†é¢‘ID: {video_id}")
                return video_id
        
        # å…¶ä»–æ¨¡å¼
        other_patterns = [
            r'/collection/(\d+)',
            r'/music/(\d+)'
        ]
        
        for pattern in other_patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        # å°è¯•ä»URLä¸­æå–æ•°å­—ID
        number_match = re.search(r'(\d{15,20})', url)
        if number_match:
            video_id = number_match.group(1)
            logger.info(f"ä»URLæå–åˆ°æ•°å­—ID: {video_id}")
            return video_id
        
        logger.error(f"æ— æ³•ä»URLæå–ID: {url}")
        return None

    def _get_aweme_id_from_info(self, info: Dict) -> Optional[str]:
        """ä» aweme ä¿¡æ¯ä¸­æå– aweme_id"""
        try:
            if 'aweme_id' in info:
                return str(info.get('aweme_id'))
            # aweme_detail ç»“æ„
            return str(info.get('aweme', {}).get('aweme_id') or info.get('aweme_id'))
        except Exception:
            return None

    def _get_sec_uid_from_info(self, info: Dict) -> Optional[str]:
        """ä» aweme ä¿¡æ¯ä¸­æå–ä½œè€… sec_uid"""
        try:
            return info.get('author', {}).get('sec_uid')
        except Exception:
            return None

    def _should_skip_increment(self, context: str, info: Dict, mix_id: Optional[str] = None, music_id: Optional[str] = None, sec_uid: Optional[str] = None) -> bool:
        """æ ¹æ®å¢é‡é…ç½®ä¸æ•°æ®åº“è®°å½•åˆ¤æ–­æ˜¯å¦è·³è¿‡ä¸‹è½½"""
        if not self.db:
            return False
        aweme_id = self._get_aweme_id_from_info(info)
        if not aweme_id:
            return False

        try:
            if context == 'post' and self.increase_cfg.get('post', False):
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                return bool(self.db.get_user_post(sec, int(aweme_id)) if aweme_id.isdigit() else None)
            if context == 'like' and self.increase_cfg.get('like', False):
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                return bool(self.db.get_user_like(sec, int(aweme_id)) if aweme_id.isdigit() else None)
            if context == 'mix' and self.increase_cfg.get('mix', False):
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                mid = mix_id or ''
                return bool(self.db.get_mix(sec, mid, int(aweme_id)) if aweme_id.isdigit() else None)
            if context == 'music' and self.increase_cfg.get('music', False):
                mid = music_id or ''
                return bool(self.db.get_music(mid, int(aweme_id)) if aweme_id.isdigit() else None)
        except Exception:
            return False
        return False

    def _record_increment(self, context: str, info: Dict, mix_id: Optional[str] = None, music_id: Optional[str] = None, sec_uid: Optional[str] = None):
        """ä¸‹è½½æˆåŠŸåå†™å…¥æ•°æ®åº“è®°å½•"""
        if not self.db:
            return
        aweme_id = self._get_aweme_id_from_info(info)
        if not aweme_id or not aweme_id.isdigit():
            return
        try:
            if context == 'post':
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                self.db.insert_user_post(sec, int(aweme_id), info)
            elif context == 'like':
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                self.db.insert_user_like(sec, int(aweme_id), info)
            elif context == 'mix':
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                mid = mix_id or ''
                self.db.insert_mix(sec, mid, int(aweme_id), info)
            elif context == 'music':
                mid = music_id or ''
                self.db.insert_music(mid, int(aweme_id), info)
        except Exception:
            pass
    
    async def download_single_video(self, url: str, progress=None, task_id=None) -> bool:
        """ä¸‹è½½å•ä¸ªè§†é¢‘/å›¾æ–‡"""
        start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        try:
            # è§£æçŸ­é“¾æ¥
            url = await self.resolve_short_url(url)

            # æå–ID
            video_id = self.extract_id_from_url(url, ContentType.VIDEO)
            if not video_id:
                logger.error(f"æ— æ³•ä»URLæå–ID: {url}")
                return False

            # å¦‚æœæ²¡æœ‰æå–åˆ°è§†é¢‘IDï¼Œå°è¯•ä½œä¸ºè§†é¢‘IDç›´æ¥ä½¿ç”¨
            if not video_id and '/user/' not in url:
                # å¯èƒ½çŸ­é“¾æ¥ç›´æ¥åŒ…å«äº†è§†é¢‘ID
                video_id = url.split('/')[-2] if url.endswith('/') else url.split('/')[-1]
                logger.debug(f"å°è¯•ä»çŸ­é“¾æ¥è·¯å¾„æå–ID: {video_id}")

            if not video_id:
                logger.error(f"æ— æ³•ä»URLæå–è§†é¢‘ID: {url}")
                return False

            # é™é€Ÿ
            await self.rate_limiter.acquire()

            # è·å–è§†é¢‘ä¿¡æ¯
            if progress and task_id is not None:
                progress.update(task_id, description="[yellow]è·å–è§†é¢‘ä¿¡æ¯...[/yellow]", completed=20)

            video_info = await self.retry_manager.execute_with_retry(
                self._fetch_video_info, video_id
            )

            if not video_info:
                logger.error(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {video_id}")
                self.stats.failed += 1
                return False

            # ä¸‹è½½è§†é¢‘æ–‡ä»¶
            if progress and task_id is not None:
                desc = video_info.get('desc', 'æ— æ ‡é¢˜')[:30]
                media_type = 'å›¾æ–‡' if video_info.get('images') else 'è§†é¢‘'
                progress.update(task_id, description=f"[cyan]ä¸‹è½½{media_type}: {desc}[/cyan]", completed=40)

            success = await self._download_media_files(video_info, progress, task_id)

            if success:
                self.stats.success += 1
                logger.debug(f"ä¸‹è½½æˆåŠŸ: {url}")
                # è®°å½•æˆåŠŸçš„ä¸‹è½½
                self.download_logger.add_success({
                    "url": url,
                    "title": video_info.get('desc', 'æ— æ ‡é¢˜'),
                    "video_id": video_id,
                    "file_path": str(self.save_path),
                    "download_time": time.time() - start_time if 'start_time' in locals() else 0
                })
            else:
                self.stats.failed += 1
                logger.error(f"ä¸‹è½½å¤±è´¥: {url}")
                # è®°å½•å¤±è´¥çš„ä¸‹è½½
                self.download_logger.add_failure({
                    "url": url,
                    "title": video_info.get('desc', 'æ— æ ‡é¢˜') if video_info else 'æ— æ³•è·å–æ ‡é¢˜',
                    "video_id": video_id,
                    "error_message": "ä¸‹è½½åª’ä½“æ–‡ä»¶å¤±è´¥"
                })

            return success

        except Exception as e:
            logger.error(f"ä¸‹è½½è§†é¢‘å¼‚å¸¸ {url}: {e}")
            self.stats.failed += 1
            # è®°å½•å¼‚å¸¸çš„ä¸‹è½½
            self.download_logger.add_failure({
                "url": url,
                "video_id": video_id if 'video_id' in locals() else '',
                "error_message": str(e),
                "error_type": "å¼‚å¸¸"
            })
            return False
        finally:
            self.stats.total += 1
    
    async def _fetch_video_info(self, video_id: str) -> Optional[Dict]:
        """è·å–è§†é¢‘ä¿¡æ¯"""
        try:
            # ç›´æ¥ä½¿ç”¨ DouYinCommand.py ä¸­æˆåŠŸçš„ Douyin ç±»
            from apiproxy.douyin.douyin import Douyin
            
            # åˆ›å»º Douyin å®ä¾‹
            dy = Douyin(database=False)
            
            # è®¾ç½®æˆ‘ä»¬çš„ cookies åˆ° douyin_headers
            if hasattr(self, 'cookies') and self.cookies:
                cookie_str = self._build_cookie_string()
                if cookie_str:
                    from apiproxy.douyin import douyin_headers
                    douyin_headers['Cookie'] = cookie_str
                    logger.info(f"è®¾ç½® Cookie åˆ° Douyin ç±»: {cookie_str[:100]}...")
            
            try:
                # ä½¿ç”¨ç°æœ‰çš„æˆåŠŸå®ç°
                result = dy.getAwemeInfo(video_id)
                if result:
                    logger.info(f"Douyin ç±»æˆåŠŸè·å–è§†é¢‘ä¿¡æ¯: {result.get('desc', '')[:30]}")
                    return result
                else:
                    logger.error("Douyin ç±»è¿”å›ç©ºç»“æœ")
                    
            except Exception as e:
                logger.error(f"Douyin ç±»è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
                
        except Exception as e:
            logger.error(f"å¯¼å…¥æˆ–ä½¿ç”¨ Douyin ç±»å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # å¦‚æœ Douyin ç±»å¤±è´¥ï¼Œå°è¯•å¢å¼ºçš„å¤‡ç”¨æ¥å£
        try:
            # å°è¯•ä½¿ç”¨å¸¦X-Bogusçš„å®˜æ–¹API
            params = self._build_detail_params(video_id)

            # ç”ŸæˆX-Bogusç­¾å
            try:
                x_bogus = get_x_bogus(params, douyin_headers.get('User-Agent'))
                api_url = f"https://www.douyin.com/aweme/v1/web/aweme/detail/?{params}&X-Bogus={x_bogus}"
                logger.info(f"å°è¯•ä½¿ç”¨X-Bogusç­¾åçš„API: {api_url[:100]}...")
            except Exception as e:
                logger.warning(f"ç”ŸæˆX-Boguså¤±è´¥: {e}, ä½¿ç”¨æ— ç­¾åå¤‡ç”¨æ¥å£")
                api_url = f"https://www.iesdouyin.com/web/api/v2/aweme/iteminfo/?item_ids={video_id}"

            # è®¾ç½®æ›´å®Œæ•´çš„è¯·æ±‚å¤´
            headers = {**douyin_headers}
            headers.update({
                'Referer': 'https://www.douyin.com/',
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive'
            })

            # æ·»åŠ Cookieå’ŒmsToken
            if hasattr(self, 'cookies') and self.cookies:
                cookie_str = self._build_cookie_string()
                if cookie_str:
                    if 'msToken=' not in cookie_str:
                        cookie_str += f'; msToken={self.mstoken}'
                    headers['Cookie'] = cookie_str
            else:
                headers['Cookie'] = f'msToken={self.mstoken}'

            async with aiohttp.ClientSession() as session:
                async with session.get(api_url, headers=headers, timeout=15) as response:
                    logger.info(f"å¤‡ç”¨æ¥å£å“åº”çŠ¶æ€: {response.status}")
                    if response.status != 200:
                        logger.error(f"å¤‡ç”¨æ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None

                    text = await response.text()
                    logger.info(f"å¤‡ç”¨æ¥å£å“åº”å†…å®¹é•¿åº¦: {len(text)}")

                    if not text:
                        logger.error("å¤‡ç”¨æ¥å£å“åº”ä¸ºç©º")
                        return None

                    try:
                        data = json.loads(text)

                        # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
                        if 'aweme_detail' in data:
                            aweme_detail = data['aweme_detail']
                            logger.info("å¤‡ç”¨æ¥å£æˆåŠŸè·å–è§†é¢‘ä¿¡æ¯ï¼ˆaweme_detailæ ¼å¼ï¼‰")
                            return aweme_detail
                        elif 'item_list' in data:
                            item_list = data.get('item_list', [])
                            if item_list:
                                aweme_detail = item_list[0]
                                logger.info("å¤‡ç”¨æ¥å£æˆåŠŸè·å–è§†é¢‘ä¿¡æ¯ï¼ˆitem_listæ ¼å¼ï¼‰")
                                return aweme_detail
                        else:
                            logger.error(f"å¤‡ç”¨æ¥å£è¿”å›æœªçŸ¥æ ¼å¼: {list(data.keys())}")

                    except json.JSONDecodeError as e:
                        logger.error(f"å¤‡ç”¨æ¥å£JSONè§£æå¤±è´¥: {e}")
                        logger.error(f"åŸå§‹å“åº”å†…å®¹: {text[:500]}...")
                        return None

        except Exception as e:
            logger.error(f"å¤‡ç”¨æ¥å£è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")

        # æœ€åçš„é™çº§ç­–ç•¥ï¼šHTMLè§£æ
        return await self._try_html_parse(video_id)
    
    def _build_detail_params(self, aweme_id: str) -> str:
        """æ„å»ºè¯¦æƒ…APIå‚æ•°"""
        # ä½¿ç”¨å¢å¼ºçš„å‚æ•°æ ¼å¼ï¼ŒåŒ…å«å¿…è¦çš„è®¾å¤‡æŒ‡çº¹ä¿¡æ¯
        params = [
            f'aweme_id={aweme_id}',
            'device_platform=webapp',
            'aid=6383',
            'channel=channel_pc_web',
            'pc_client_type=1',
            'version_code=170400',
            'version_name=17.4.0',
            'cookie_enabled=true',
            'screen_width=1920',
            'screen_height=1080',
            'browser_language=zh-CN',
            'browser_platform=MacIntel',
            'browser_name=Chrome',
            'browser_version=122.0.0.0',
            'browser_online=true',
            'engine_name=Blink',
            'engine_version=122.0.0.0',
            'os_name=Mac',
            'os_version=10.15.7',
            'cpu_core_num=8',
            'device_memory=8',
            'platform=PC',
            'downlink=10',
            'effective_type=4g',
            'round_trip_time=50',
            f'msToken={self.mstoken}',
            f'device_id={self.device_id}',
        ]
        return '&'.join(params)

    async def _try_html_parse(self, video_id: str) -> Optional[Dict]:
        """HTMLè§£æé™çº§ç­–ç•¥ - å½“APIéƒ½å¤±è´¥æ—¶å°è¯•ä»ç½‘é¡µè§£æ"""
        try:
            logger.info("å°è¯•HTMLè§£æç­–ç•¥è·å–è§†é¢‘ä¿¡æ¯")

            # æ„å»ºç½‘é¡µURL
            share_url = f"https://www.iesdouyin.com/share/video/{video_id}/"

            # è®¾ç½®æ¨¡æ‹Ÿæµè§ˆå™¨çš„è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Upgrade-Insecure-Requests': '1'
            }

            async with aiohttp.ClientSession() as session:
                async with session.get(share_url, headers=headers, timeout=20) as response:
                    if response.status != 200:
                        logger.warning(f"HTMLé¡µé¢è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None

                    html = await response.text()
                    if not html:
                        logger.warning("HTMLé¡µé¢å†…å®¹ä¸ºç©º")
                        return None

                    # è§£æHTMLå†…å®¹
                    return self._parse_html_content(html, video_id)

        except Exception as e:
            logger.error(f"HTMLè§£æç­–ç•¥å¤±è´¥: {e}")
            return None

    def _parse_html_content(self, html: str, video_id: str) -> Optional[Dict]:
        """è§£æHTMLå†…å®¹æå–è§†é¢‘ä¿¡æ¯"""
        import re
        import urllib.parse

        try:
            # æ–¹æ³•1ï¼šä»RENDER_DATAè„šæœ¬æ ‡ç­¾ä¸­æå–
            render_data_pattern = r'<script id="RENDER_DATA" type="application/json">(.*?)</script>'
            match = re.search(render_data_pattern, html, re.DOTALL)

            if match:
                try:
                    # URLè§£ç 
                    data_str = urllib.parse.unquote(match.group(1))
                    data = json.loads(data_str)

                    # éå†æ•°æ®æŸ¥æ‰¾è§†é¢‘ä¿¡æ¯
                    for key, value in data.items():
                        if isinstance(value, dict):
                            # æŸ¥æ‰¾åŒ…å«awemeä¿¡æ¯çš„èŠ‚ç‚¹
                            if 'aweme' in str(value).lower():
                                aweme_data = self._extract_aweme_from_render_data(value)
                                if aweme_data:
                                    logger.info("HTMLè§£ææˆåŠŸï¼ˆRENDER_DATAæ–¹å¼ï¼‰")
                                    return aweme_data

                except Exception as e:
                    logger.debug(f"è§£æRENDER_DATAå¤±è´¥: {e}")

            # æ–¹æ³•2ï¼šä»å…¶ä»–scriptæ ‡ç­¾ä¸­æå–è§†é¢‘ä¿¡æ¯
            script_patterns = [
                r'window\._SSR_HYDRATED_DATA\s*=\s*({.*?});',
                r'window\.INITIAL_STATE\s*=\s*({.*?});',
                r'__INITIAL_STATE__\s*=\s*({.*?});',
                r'window\.__NUXT__\s*=\s*({.*?});'
            ]

            for pattern in script_patterns:
                matches = re.finditer(pattern, html, re.DOTALL)
                for match in matches:
                    try:
                        data_str = match.group(1)
                        data = json.loads(data_str)
                        aweme_data = self._extract_aweme_from_script_data(data, video_id)
                        if aweme_data:
                            logger.info(f"HTMLè§£ææˆåŠŸï¼ˆscriptæ–¹å¼ï¼‰")
                            return aweme_data
                    except Exception as e:
                        logger.debug(f"è§£æscriptæ•°æ®å¤±è´¥: {e}")

            # æ–¹æ³•3ï¼šæå–metaæ ‡ç­¾ä¸­çš„ä¿¡æ¯
            meta_info = self._extract_meta_info(html)
            if meta_info:
                # æ„å»ºåŸºç¡€çš„awemeç»“æ„
                basic_aweme = {
                    'aweme_id': video_id,
                    'desc': meta_info.get('description', ''),
                    'create_time': int(time.time()),  # ä½¿ç”¨å½“å‰æ—¶é—´æˆ³ä½œä¸ºåˆ›å»ºæ—¶é—´
                    'author': {
                        'nickname': meta_info.get('author', 'unknown'),
                        'unique_id': meta_info.get('author', 'unknown'),
                        'sec_uid': ''
                    },
                    'statistics': {
                        'digg_count': 0,
                        'comment_count': 0,
                        'share_count': 0,
                        'play_count': 0
                    },
                    'video': {
                        'play_addr': {'url_list': []},
                        'download_addr': {'url_list': []},
                        'cover': {'url_list': [meta_info.get('cover', '')]}
                    },
                    'music': {
                        'title': '',
                        'play_url': {'url_list': []}
                    }
                }
                logger.info("HTMLè§£ææˆåŠŸï¼ˆmetaæ ‡ç­¾æ–¹å¼ï¼ŒåŸºç¡€ä¿¡æ¯ï¼‰")
                return basic_aweme

            logger.warning("HTMLè§£ææœªèƒ½æå–åˆ°æœ‰æ•ˆçš„è§†é¢‘ä¿¡æ¯")
            return None

        except Exception as e:
            logger.error(f"HTMLå†…å®¹è§£æå¤±è´¥: {e}")
            return None

    def _extract_aweme_from_render_data(self, data: Dict) -> Optional[Dict]:
        """ä»RENDER_DATAä¸­æå–awemeä¿¡æ¯"""
        try:
            # é€’å½’æœç´¢awemeç›¸å…³æ•°æ®
            if isinstance(data, dict):
                for key, value in data.items():
                    if 'aweme' in key.lower() and isinstance(value, dict):
                        if 'aweme_id' in value or 'video' in value:
                            return value
                    elif isinstance(value, (dict, list)):
                        result = self._extract_aweme_from_render_data(value)
                        if result:
                            return result
            elif isinstance(data, list):
                for item in data:
                    if isinstance(item, (dict, list)):
                        result = self._extract_aweme_from_render_data(item)
                        if result:
                            return result
        except Exception:
            pass
        return None

    def _extract_aweme_from_script_data(self, data: Dict, video_id: str) -> Optional[Dict]:
        """ä»scriptæ•°æ®ä¸­æå–awemeä¿¡æ¯"""
        try:
            # é€’å½’æœç´¢åŒ…å«video_idçš„awemeæ•°æ®
            if isinstance(data, dict):
                if data.get('aweme_id') == video_id:
                    return data
                for value in data.values():
                    if isinstance(value, (dict, list)):
                        result = self._extract_aweme_from_script_data(value, video_id)
                        if result:
                            return result
            elif isinstance(data, list):
                for item in data:
                    if isinstance(item, (dict, list)):
                        result = self._extract_aweme_from_script_data(item, video_id)
                        if result:
                            return result
        except Exception:
            pass
        return None

    def _extract_meta_info(self, html: str) -> Dict:
        """ä»metaæ ‡ç­¾ä¸­æå–åŸºç¡€ä¿¡æ¯"""
        import re

        meta_info = {}

        # æå–æ ‡é¢˜/æè¿°
        title_pattern = r'<title[^>]*>(.*?)</title>'
        title_match = re.search(title_pattern, html, re.IGNORECASE | re.DOTALL)
        if title_match:
            meta_info['description'] = title_match.group(1).strip()

        # æå–metaæè¿°
        desc_pattern = r'<meta[^>]+name=["\']description["\'][^>]+content=["\']([^"\']*)["\']'
        desc_match = re.search(desc_pattern, html, re.IGNORECASE)
        if desc_match:
            meta_info['description'] = desc_match.group(1).strip()

        # æå–ä½œè€…ä¿¡æ¯
        author_patterns = [
            r'<meta[^>]+name=["\']author["\'][^>]+content=["\']([^"\']*)["\']',
            r'@([^@\s]+)',  # ä»æ ‡é¢˜ä¸­æå–@ç”¨æˆ·å
        ]

        for pattern in author_patterns:
            author_match = re.search(pattern, html, re.IGNORECASE)
            if author_match:
                meta_info['author'] = author_match.group(1).strip()
                break

        # æå–å°é¢å›¾
        cover_patterns = [
            r'<meta[^>]+property=["\']og:image["\'][^>]+content=["\']([^"\']*)["\']',
            r'<meta[^>]+name=["\']twitter:image["\'][^>]+content=["\']([^"\']*)["\']'
        ]

        for pattern in cover_patterns:
            cover_match = re.search(pattern, html, re.IGNORECASE)
            if cover_match:
                meta_info['cover'] = cover_match.group(1).strip()
                break

        return meta_info

    def _enhance_video_url(self, url: str) -> str:
        """å¢å¼ºè§†é¢‘URLï¼Œå°è¯•è·å–æ›´é«˜è´¨é‡çš„ç‰ˆæœ¬"""
        if not url:
            return url

        # æ›¿æ¢ä¸ºæ— æ°´å°ç‰ˆæœ¬
        enhanced_url = url.replace('playwm', 'play')

        # å°è¯•è·å–æ›´é«˜è´¨é‡
        quality_replacements = [
            ('720p', '1080p'),
            ('480p', '720p'),
            ('360p', '480p'),
        ]

        for old_quality, new_quality in quality_replacements:
            if old_quality in enhanced_url:
                enhanced_url = enhanced_url.replace(old_quality, new_quality)
                break

        logger.debug(f"URLå¢å¼º: {url} -> {enhanced_url}")
        return enhanced_url

    def _get_fallback_user_agent(self) -> str:
        """è·å–å¤‡ç”¨User-Agent"""
        user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2.1 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0'
        ]
        import random
        return random.choice(user_agents)

    async def _validate_video_info(self, video_info: Dict) -> bool:
        """éªŒè¯è§†é¢‘ä¿¡æ¯çš„å®Œæ•´æ€§"""
        if not video_info:
            return False

        # åŸºæœ¬å­—æ®µæ£€æŸ¥
        required_fields = ['aweme_id']
        for field in required_fields:
            if field not in video_info:
                logger.warning(f"è§†é¢‘ä¿¡æ¯ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                return False

        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ä¸‹è½½çš„å†…å®¹
        has_video = bool(video_info.get('video', {}).get('play_addr', {}).get('url_list'))
        has_images = bool(video_info.get('images'))

        if not has_video and not has_images:
            logger.warning("è§†é¢‘ä¿¡æ¯ä¸­æ²¡æœ‰å¯ä¸‹è½½çš„åª’ä½“å†…å®¹")
            return False

        return True

    async def _get_alternative_endpoints(self, aweme_id: str) -> List[str]:
        """è·å–å¤‡ç”¨APIç«¯ç‚¹åˆ—è¡¨"""
        endpoints = [
            f"https://www.douyin.com/aweme/v1/web/aweme/detail/?aweme_id={aweme_id}",
            f"https://www.iesdouyin.com/aweme/v1/web/aweme/detail/?aweme_id={aweme_id}",
            f"https://www.iesdouyin.com/web/api/v2/aweme/iteminfo/?item_ids={aweme_id}",
            f"https://aweme.snssdk.com/aweme/v1/aweme/detail/?aweme_id={aweme_id}",
        ]

        # ä¸ºæ¯ä¸ªç«¯ç‚¹æ·»åŠ å®Œæ•´å‚æ•°
        enhanced_endpoints = []
        for endpoint in endpoints:
            if '?' in endpoint:
                base_url, existing_params = endpoint.split('?', 1)
                full_params = existing_params + '&' + self._build_detail_params(aweme_id).replace(f'aweme_id={aweme_id}&', '')
            else:
                full_params = self._build_detail_params(aweme_id)
                base_url = endpoint

            enhanced_endpoints.append(f"{base_url}?{full_params}")

        return enhanced_endpoints

    async def _download_media_files(self, video_info: Dict, progress=None, task_id=None) -> bool:
        """ä¸‹è½½åª’ä½“æ–‡ä»¶"""
        try:
            # åˆ¤æ–­ç±»å‹
            is_image = bool(video_info.get('images'))

            # æ„å»ºä¿å­˜è·¯å¾„
            author_name = video_info.get('author', {}).get('nickname', 'unknown')
            desc = video_info.get('desc', '')[:50].replace('/', '_')
            # å…¼å®¹ create_time ä¸ºæ—¶é—´æˆ³æˆ–æ ¼å¼åŒ–å­—ç¬¦ä¸²
            raw_create_time = video_info.get('create_time')
            dt_obj = None
            if isinstance(raw_create_time, (int, float)):
                dt_obj = datetime.fromtimestamp(raw_create_time)
            elif isinstance(raw_create_time, str) and raw_create_time:
                for fmt in ('%Y-%m-%d %H.%M.%S', '%Y-%m-%d_%H-%M-%S', '%Y-%m-%d %H:%M:%S'):
                    try:
                        dt_obj = datetime.strptime(raw_create_time, fmt)
                        break
                    except Exception:
                        pass
            if dt_obj is None:
                dt_obj = datetime.fromtimestamp(time.time())
            create_time = dt_obj.strftime('%Y-%m-%d_%H-%M-%S')

            folder_name = f"{create_time}_{desc}" if desc else create_time
            save_dir = self.save_path / author_name / folder_name
            save_dir.mkdir(parents=True, exist_ok=True)

            success = True

            if is_image:
                # ä¸‹è½½å›¾æ–‡ï¼ˆæ— æ°´å°ï¼‰
                images = video_info.get('images', [])
                total_images = len(images)

                for i, img in enumerate(images, 1):
                    img_url = self._get_best_quality_url(img.get('url_list', []))
                    if img_url:
                        file_path = save_dir / f"image_{i}.jpg"
                        # æ›´æ–°è¿›åº¦æè¿°
                        if progress and task_id is not None:
                            progress.update(
                                task_id,
                                description=f"[cyan]ä¸‹è½½å›¾ç‰‡ {i}/{total_images}: {file_path.name}[/cyan]",
                                completed=(i - 1) * 100 / total_images
                            )

                        if await self._download_file_with_progress(img_url, file_path, progress, task_id, i, total_images):
                            logger.debug(f"ä¸‹è½½å›¾ç‰‡ {i}/{total_images}: {file_path.name}")
                        else:
                            success = False

                # æ›´æ–°å®ŒæˆçŠ¶æ€
                if progress and task_id is not None:
                    progress.update(task_id, completed=100, description=f"[green]âœ“ ä¸‹è½½å®Œæˆ {total_images} å¼ å›¾ç‰‡[/green]")
            else:
                # ä¸‹è½½è§†é¢‘ï¼ˆæ— æ°´å°ï¼‰
                video_url = self._get_no_watermark_url(video_info)
                if video_url:
                    file_path = save_dir / f"{folder_name}.mp4"
                    if progress and task_id is not None:
                        progress.update(task_id, description=f"[cyan]ä¸‹è½½è§†é¢‘: {file_path.name}[/cyan]")

                    if await self._download_file_with_progress(video_url, file_path, progress, task_id):
                        logger.debug(f"ä¸‹è½½è§†é¢‘: {file_path.name}")
                    else:
                        success = False

                # ä¸‹è½½éŸ³é¢‘
                if self.config.get('music', True):
                    music_url = self._get_music_url(video_info)
                    if music_url:
                        file_path = save_dir / f"{folder_name}_music.mp3"
                        if progress and task_id is not None:
                            progress.update(task_id, description=f"[dim]ä¸‹è½½éŸ³é¢‘...[/dim]")
                        await self._download_file(music_url, file_path)

                # æ›´æ–°å®ŒæˆçŠ¶æ€
                if progress and task_id is not None:
                    progress.update(task_id, completed=100, description=f"[green]âœ“ ä¸‹è½½å®Œæˆ[/green]")

            # ä¸‹è½½å°é¢
            if self.config.get('cover', True):
                cover_url = self._get_cover_url(video_info)
                if cover_url:
                    file_path = save_dir / f"{folder_name}_cover.jpg"
                    await self._download_file(cover_url, file_path)

            # ä¿å­˜JSONæ•°æ®
            if self.config.get('json', True):
                json_path = save_dir / f"{folder_name}_data.json"
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(video_info, f, ensure_ascii=False, indent=2)

            return success

        except Exception as e:
            logger.error(f"ä¸‹è½½åª’ä½“æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _get_no_watermark_url(self, video_info: Dict) -> Optional[str]:
        """è·å–æ— æ°´å°è§†é¢‘URL"""
        try:
            # ä¼˜å…ˆä½¿ç”¨play_addr_h264
            play_addr = video_info.get('video', {}).get('play_addr_h264') or \
                       video_info.get('video', {}).get('play_addr')

            if play_addr:
                url_list = play_addr.get('url_list', [])
                if url_list:
                    # ä½¿ç”¨å¢å¼ºçš„URLå¤„ç†
                    url = self._enhance_video_url(url_list[0])
                    return url

            # å¤‡ç”¨ï¼šdownload_addr
            download_addr = video_info.get('video', {}).get('download_addr')
            if download_addr:
                url_list = download_addr.get('url_list', [])
                if url_list:
                    return self._enhance_video_url(url_list[0])

            # å†æ¬¡å¤‡ç”¨ï¼šbit_rateæ•°ç»„ä¸­çš„URL
            bit_rate_list = video_info.get('video', {}).get('bit_rate', [])
            for bit_rate in bit_rate_list:
                play_addr = bit_rate.get('play_addr', {})
                url_list = play_addr.get('url_list', [])
                if url_list:
                    return self._enhance_video_url(url_list[0])

        except Exception as e:
            logger.error(f"è·å–æ— æ°´å°URLå¤±è´¥: {e}")

        return None
    
    def _get_best_quality_url(self, url_list: List[str]) -> Optional[str]:
        """è·å–æœ€é«˜è´¨é‡çš„URL"""
        if not url_list:
            return None
        
        # ä¼˜å…ˆé€‰æ‹©åŒ…å«ç‰¹å®šå…³é”®è¯çš„URL
        for keyword in ['1080', 'origin', 'high']:
            for url in url_list:
                if keyword in url:
                    return url
        
        # è¿”å›ç¬¬ä¸€ä¸ª
        return url_list[0]
    
    def _get_music_url(self, video_info: Dict) -> Optional[str]:
        """è·å–éŸ³ä¹URL"""
        try:
            music = video_info.get('music', {})
            play_url = music.get('play_url', {})
            url_list = play_url.get('url_list', [])
            return url_list[0] if url_list else None
        except:
            return None
    
    def _get_cover_url(self, video_info: Dict) -> Optional[str]:
        """è·å–å°é¢URL"""
        try:
            cover = video_info.get('video', {}).get('cover', {})
            url_list = cover.get('url_list', [])
            return self._get_best_quality_url(url_list)
        except:
            return None
    
    async def _download_file(self, url: str, save_path: Path) -> bool:
        """ä¸‹è½½æ–‡ä»¶"""
        try:
            if save_path.exists():
                logger.debug(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {save_path.name}")
                return True

            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=self.headers) as response:
                    if response.status == 200:
                        content = await response.read()
                        with open(save_path, 'wb') as f:
                            f.write(content)
                        return True
                    else:
                        logger.error(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return False

        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥ {url}: {e}")
            return False

    async def _download_file_with_progress(self, url: str, save_path: Path, progress=None, task_id=None, current=1, total=1) -> bool:
        """å¸¦è¿›åº¦æ˜¾ç¤ºçš„æ–‡ä»¶ä¸‹è½½"""
        try:
            if save_path.exists():
                logger.debug(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {save_path.name}")
                return True

            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=self.headers) as response:
                    if response.status == 200:
                        total_size = int(response.headers.get('content-length', 0))
                        chunk_size = 8192
                        downloaded = 0

                        with open(save_path, 'wb') as f:
                            async for chunk in response.content.iter_chunked(chunk_size):
                                f.write(chunk)
                                downloaded += len(chunk)

                                # æ›´æ–°è¿›åº¦
                                if progress and task_id is not None and total_size > 0:
                                    if total > 1:
                                        # å¤šæ–‡ä»¶æƒ…å†µä¸‹çš„è¿›åº¦è®¡ç®—
                                        file_progress = downloaded / total_size
                                        overall_progress = ((current - 1) + file_progress) * 100 / total
                                        progress.update(task_id, completed=overall_progress)
                                    else:
                                        # å•æ–‡ä»¶è¿›åº¦
                                        progress.update(task_id, completed=downloaded * 100 / total_size)

                        return True
                    else:
                        logger.error(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return False

        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    async def download_user_page(self, url: str) -> bool:
        """ä¸‹è½½ç”¨æˆ·ä¸»é¡µå†…å®¹"""
        try:
            # æå–ç”¨æˆ·ID
            user_id = self.extract_id_from_url(url, ContentType.USER)
            if not user_id:
                logger.error(f"æ— æ³•ä»URLæå–ç”¨æˆ·ID: {url}")
                return False
            
            console.print(f"\n[cyan]æ­£åœ¨è·å–ç”¨æˆ· {user_id} çš„ä½œå“åˆ—è¡¨...[/cyan]")
            
            # æ ¹æ®é…ç½®ä¸‹è½½ä¸åŒç±»å‹çš„å†…å®¹
            mode = self.config.get('mode', ['post'])
            if isinstance(mode, str):
                mode = [mode]
            
            # å¢åŠ æ€»ä»»åŠ¡æ•°ç»Ÿè®¡
            total_posts = 0
            if 'post' in mode:
                total_posts += self.config.get('number', {}).get('post', 0) or 1
            if 'like' in mode:
                total_posts += self.config.get('number', {}).get('like', 0) or 1
            if 'mix' in mode:
                total_posts += self.config.get('number', {}).get('allmix', 0) or 1
            
            self.stats.total += total_posts
            
            for m in mode:
                if m == 'post':
                    await self._download_user_posts(user_id)
                elif m == 'like':
                    await self._download_user_likes(user_id)
                elif m == 'mix':
                    await self._download_user_mixes(user_id)
            
            return True
            
        except Exception as e:
            logger.error(f"ä¸‹è½½ç”¨æˆ·ä¸»é¡µå¤±è´¥: {e}")
            return False
    
    async def _download_user_posts(self, user_id: str):
        """ä¸‹è½½ç”¨æˆ·å‘å¸ƒçš„ä½œå“"""
        max_count = self.config.get('number', {}).get('post', 0)
        cursor = 0
        downloaded = 0
        skipped = 0

        console.print(f"\n[bold cyan]ğŸ“¥ å¼€å§‹ä¸‹è½½ç”¨æˆ·å‘å¸ƒçš„ä½œå“[/bold cyan]")
        console.print(f"[dim]ç”¨æˆ·ID: {user_id}[/dim]")
        if max_count > 0:
            console.print(f"[dim]é™åˆ¶æ•°é‡: {max_count}[/dim]")

        # åˆ›å»ºç‹¬ç«‹çš„Progresså®ä¾‹ï¼Œé¿å…å†²çª
        progress = Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(bar_width=40),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TextColumn("[dim]â€¢[/dim]"),
            TimeRemainingColumn(),
            console=console,
            refresh_per_second=2,
            transient=True  # å®Œæˆåæ¸…é™¤
        )

        with progress:

            # ä¸»ä»»åŠ¡è¿›åº¦æ¡
            main_task = progress.add_task(
                "[yellow]è·å–ä½œå“åˆ—è¡¨...[/yellow]",
                total=None
            )

            while True:
                # é™é€Ÿ
                await self.rate_limiter.acquire()

                # è·å–ä½œå“åˆ—è¡¨
                posts_data = await self._fetch_user_posts(user_id, cursor)
                if not posts_data:
                    break

                aweme_list = posts_data.get('aweme_list', [])
                if not aweme_list:
                    break

                # æ›´æ–°ä¸»ä»»åŠ¡
                progress.update(
                    main_task,
                    description=f"[cyan]å¤„ç†ä½œå“æ‰¹æ¬¡ (å·²ä¸‹è½½: {downloaded}, å·²è·³è¿‡: {skipped})[/cyan]"
                )

                # ä¸‹è½½ä½œå“
                for aweme in aweme_list:
                    if max_count > 0 and downloaded >= max_count:
                        console.print(f"\n[yellow]âš ï¸ å·²è¾¾åˆ°ä¸‹è½½æ•°é‡é™åˆ¶: {max_count}[/yellow]")
                        return

                    # æ—¶é—´è¿‡æ»¤
                    if not self._check_time_filter(aweme):
                        skipped += 1
                        continue

                    # å¢é‡åˆ¤æ–­
                    if self._should_skip_increment('post', aweme, sec_uid=user_id):
                        skipped += 1
                        continue

                    # è·å–ä½œå“ä¿¡æ¯
                    desc = aweme.get('desc', 'æ— æ ‡é¢˜')[:30]
                    aweme_type = 'å›¾æ–‡' if aweme.get('images') else 'è§†é¢‘'

                    # åˆ›å»ºä¸‹è½½ä»»åŠ¡
                    task_id = progress.add_task(
                        f"[cyan]{aweme_type}[/cyan] {desc}",
                        total=100
                    )

                    # ä¸‹è½½
                    success = await self._download_media_files(aweme, progress, task_id)

                    if success:
                        downloaded += 1
                        self.stats.success += 1
                        self._record_increment('post', aweme, sec_uid=user_id)
                    else:
                        self.stats.failed += 1
                        progress.update(task_id, description=f"[red]âœ— å¤±è´¥[/red] {desc}")

                    # ç§»é™¤å®Œæˆçš„ä»»åŠ¡ï¼ˆä¿æŒç•Œé¢æ•´æ´ï¼‰
                    progress.remove_task(task_id)

                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤š
                if not posts_data.get('has_more'):
                    break

                cursor = posts_data.get('max_cursor', 0)

            # å®Œæˆä¸»ä»»åŠ¡
            progress.update(main_task, description="[green]âœ“ ä½œå“ä¸‹è½½å®Œæˆ[/green]")
            progress.remove_task(main_task)

        # æ˜¾ç¤ºç»Ÿè®¡
        console.print(f"\n[bold green]âœ… ç”¨æˆ·ä½œå“ä¸‹è½½å®Œæˆ[/bold green]")
        console.print(f"   ä¸‹è½½: {downloaded} | è·³è¿‡: {skipped} | å¤±è´¥: {self.stats.failed}")
    
    async def _fetch_user_posts(self, user_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä½œå“åˆ—è¡¨"""
        try:
            # ç›´æ¥ä½¿ç”¨ Douyin ç±»çš„ getUserInfo æ–¹æ³•ï¼Œå°±åƒ DouYinCommand.py é‚£æ ·
            from apiproxy.douyin.douyin import Douyin
            
            # åˆ›å»º Douyin å®ä¾‹
            dy = Douyin(database=False)
            
            # è·å–ç”¨æˆ·ä½œå“åˆ—è¡¨
            result = dy.getUserInfo(
                user_id, 
                "post", 
                35, 
                0,  # ä¸é™åˆ¶æ•°é‡
                False,  # ä¸å¯ç”¨å¢é‡
                "",  # start_time
                ""   # end_time
            )
            
            if result:
                logger.info(f"Douyin ç±»æˆåŠŸè·å–ç”¨æˆ·ä½œå“åˆ—è¡¨ï¼Œå…± {len(result)} ä¸ªä½œå“")
                # è½¬æ¢ä¸ºæœŸæœ›çš„æ ¼å¼
                return {
                    'status_code': 0,
                    'aweme_list': result,
                    'max_cursor': cursor,
                    'has_more': False
                }
            else:
                logger.error("Douyin ç±»è¿”å›ç©ºç»“æœ")
                return None
                
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä½œå“åˆ—è¡¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return None
    
    async def _download_user_likes(self, user_id: str):
        """ä¸‹è½½ç”¨æˆ·å–œæ¬¢çš„ä½œå“"""
        max_count = 0
        try:
            max_count = int(self.config.get('number', {}).get('like', 0))
        except Exception:
            max_count = 0
        cursor = 0
        downloaded = 0
        skipped = 0

        console.print(f"\n[bold cyan]â¤ï¸ å¼€å§‹ä¸‹è½½ç”¨æˆ·å–œæ¬¢çš„ä½œå“[/bold cyan]")
        console.print(f"[dim]ç”¨æˆ·ID: {user_id}[/dim]")
        if max_count > 0:
            console.print(f"[dim]é™åˆ¶æ•°é‡: {max_count}[/dim]")

        # åˆ›å»ºç‹¬ç«‹çš„Progresså®ä¾‹
        progress = Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(bar_width=40),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TextColumn("[dim]â€¢[/dim]"),
            TimeRemainingColumn(),
            console=console,
            refresh_per_second=2,
            transient=True
        )

        with progress:

            # ä¸»ä»»åŠ¡è¿›åº¦æ¡
            main_task = progress.add_task(
                "[yellow]è·å–å–œæ¬¢åˆ—è¡¨...[/yellow]",
                total=None
            )

            while True:
                # é™é€Ÿ
                await self.rate_limiter.acquire()

                # è·å–å–œæ¬¢åˆ—è¡¨
                likes_data = await self._fetch_user_likes(user_id, cursor)
                if not likes_data:
                    break

                aweme_list = likes_data.get('aweme_list', [])
                if not aweme_list:
                    break

                # æ›´æ–°ä¸»ä»»åŠ¡
                progress.update(
                    main_task,
                    description=f"[cyan]å¤„ç†å–œæ¬¢æ‰¹æ¬¡ (å·²ä¸‹è½½: {downloaded}, å·²è·³è¿‡: {skipped})[/cyan]"
                )

                # ä¸‹è½½ä½œå“
                for aweme in aweme_list:
                    if max_count > 0 and downloaded >= max_count:
                        console.print(f"\n[yellow]âš ï¸ å·²è¾¾åˆ°ä¸‹è½½æ•°é‡é™åˆ¶: {max_count}[/yellow]")
                        return

                    if not self._check_time_filter(aweme):
                        skipped += 1
                        continue

                    # å¢é‡åˆ¤æ–­
                    if self._should_skip_increment('like', aweme, sec_uid=user_id):
                        skipped += 1
                        continue

                    # è·å–ä½œå“ä¿¡æ¯
                    desc = aweme.get('desc', 'æ— æ ‡é¢˜')[:30]
                    aweme_type = 'å›¾æ–‡' if aweme.get('images') else 'è§†é¢‘'

                    # åˆ›å»ºä¸‹è½½ä»»åŠ¡
                    task_id = progress.add_task(
                        f"[magenta]{aweme_type}[/magenta] {desc}",
                        total=100
                    )

                    success = await self._download_media_files(aweme, progress, task_id)

                    if success:
                        downloaded += 1
                        self.stats.success += 1
                        self._record_increment('like', aweme, sec_uid=user_id)
                    else:
                        self.stats.failed += 1
                        progress.update(task_id, description=f"[red]âœ— å¤±è´¥[/red] {desc}")

                    # ç§»é™¤å®Œæˆçš„ä»»åŠ¡
                    progress.remove_task(task_id)

                # ç¿»é¡µ
                if not likes_data.get('has_more'):
                    break
                cursor = likes_data.get('max_cursor', 0)

            # å®Œæˆä¸»ä»»åŠ¡
            progress.update(main_task, description="[green]âœ“ å–œæ¬¢ä¸‹è½½å®Œæˆ[/green]")
            progress.remove_task(main_task)

        # æ˜¾ç¤ºç»Ÿè®¡
        console.print(f"\n[bold green]âœ… å–œæ¬¢ä½œå“ä¸‹è½½å®Œæˆ[/bold green]")
        console.print(f"   ä¸‹è½½: {downloaded} | è·³è¿‡: {skipped} | å¤±è´¥: {self.stats.failed}")

    async def _fetch_user_likes(self, user_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–ç”¨æˆ·å–œæ¬¢çš„ä½œå“åˆ—è¡¨"""
        try:
            params_list = [
                f'sec_user_id={user_id}',
                f'max_cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true',
                'engine_name=Blink',
                'engine_version=122.0.0.0',
                'os_name=Mac',
                'os_version=10.15.7',
                'cpu_core_num=8',
                'device_memory=8',
                'platform=PC',
                'downlink=10',
                'effective_type=4g',
                'round_trip_time=50',
                f'msToken={self.mstoken}',
                f'device_id={self.device_id}',
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.USER_FAVORITE_A

            # ä½¿ç”¨å¢å¼ºçš„ç­¾åç”Ÿæˆ
            try:
                x_bogus = get_x_bogus(params, self.headers.get('User-Agent'))
                full_url = f"{api_url}{params}&X-Bogus={x_bogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•åŸæœ‰æ–¹æ³•")
                try:
                    xbogus = self.utils.getXbogus(params)
                    full_url = f"{api_url}{params}&X-Bogus={xbogus}"
                except Exception as e2:
                    logger.warning(f"åŸæœ‰X-Bogusæ–¹æ³•ä¹Ÿå¤±è´¥: {e2}, ä½¿ç”¨æ— ç­¾å")
                    full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚ç”¨æˆ·å–œæ¬¢åˆ—è¡¨: {full_url[:100]}...")

            # ç¡®ä¿headersåŒ…å«msToken
            headers = {**self.headers}
            if 'Cookie' in headers:
                if 'msToken=' not in headers['Cookie']:
                    headers['Cookie'] += f'; msToken={self.mstoken}'
            else:
                headers['Cookie'] = f'msToken={self.mstoken}'

            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None

                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None

                    data = json.loads(text)
                    if data.get('status_code') == 0:
                        return data
                    else:
                        logger.error(f"APIè¿”å›é”™è¯¯: {data.get('status_msg', 'æœªçŸ¥é”™è¯¯')}")
                        return None
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·å–œæ¬¢åˆ—è¡¨å¤±è´¥: {e}")
        return None

    async def _download_user_mixes(self, user_id: str):
        """ä¸‹è½½ç”¨æˆ·çš„æ‰€æœ‰åˆé›†ï¼ˆæŒ‰é…ç½®å¯é™åˆ¶æ•°é‡ï¼‰"""
        max_allmix = 0
        try:
            # å…¼å®¹æ—§é”®å allmix æˆ– mix
            number_cfg = self.config.get('number', {}) or {}
            max_allmix = int(number_cfg.get('allmix', number_cfg.get('mix', 0)) or 0)
        except Exception:
            max_allmix = 0

        cursor = 0
        fetched = 0

        console.print(f"\n[green]å¼€å§‹è·å–ç”¨æˆ·åˆé›†åˆ—è¡¨...[/green]")
        while True:
            await self.rate_limiter.acquire()
            mix_list_data = await self._fetch_user_mix_list(user_id, cursor)
            if not mix_list_data:
                break

            mix_infos = mix_list_data.get('mix_infos') or []
            if not mix_infos:
                break

            for mix in mix_infos:
                if max_allmix > 0 and fetched >= max_allmix:
                    console.print(f"[yellow]å·²è¾¾åˆ°åˆé›†æ•°é‡é™åˆ¶: {max_allmix}[/yellow]")
                    return
                mix_id = mix.get('mix_id')
                mix_name = mix.get('mix_name', '')
                console.print(f"[cyan]ä¸‹è½½åˆé›†[/cyan]: {mix_name} ({mix_id})")
                await self._download_mix_by_id(mix_id)
                fetched += 1

            if not mix_list_data.get('has_more'):
                break
            cursor = mix_list_data.get('cursor', 0)

        console.print(f"[green]âœ… ç”¨æˆ·åˆé›†ä¸‹è½½å®Œæˆï¼Œå…±å¤„ç† {fetched} ä¸ª[/green]")

    async def _fetch_user_mix_list(self, user_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–ç”¨æˆ·åˆé›†åˆ—è¡¨"""
        try:
            params_list = [
                f'sec_user_id={user_id}',
                f'cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true',
                'engine_name=Blink',
                'engine_version=122.0.0.0',
                'os_name=Mac',
                'os_version=10.15.7',
                'cpu_core_num=8',
                'device_memory=8',
                'platform=PC',
                'downlink=10',
                'effective_type=4g',
                'round_trip_time=50',
                f'msToken={self.mstoken}',
                f'device_id={self.device_id}',
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.USER_MIX_LIST
            try:
                x_bogus = get_x_bogus(params, self.headers.get('User-Agent'))
                full_url = f"{api_url}{params}&X-Bogus={x_bogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•åŸæœ‰æ–¹æ³•")
                try:
                    xbogus = self.utils.getXbogus(params)
                    full_url = f"{api_url}{params}&X-Bogus={xbogus}"
                except Exception as e2:
                    logger.warning(f"åŸæœ‰X-Bogusæ–¹æ³•ä¹Ÿå¤±è´¥: {e2}, ä½¿ç”¨æ— ç­¾å")
                    full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚ç”¨æˆ·åˆé›†åˆ—è¡¨: {full_url[:100]}...")

            # ç¡®ä¿headersåŒ…å«msToken
            headers = {**self.headers}
            if 'Cookie' in headers:
                if 'msToken=' not in headers['Cookie']:
                    headers['Cookie'] += f'; msToken={self.mstoken}'
            else:
                headers['Cookie'] = f'msToken={self.mstoken}'

            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None
                    data = json.loads(text)
                    if data.get('status_code') == 0:
                        return data
                    else:
                        logger.error(f"APIè¿”å›é”™è¯¯: {data.get('status_msg', 'æœªçŸ¥é”™è¯¯')}")
                        return None
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·åˆé›†åˆ—è¡¨å¤±è´¥: {e}")
        return None

    async def download_mix(self, url: str) -> bool:
        """æ ¹æ®åˆé›†é“¾æ¥ä¸‹è½½åˆé›†å†…æ‰€æœ‰ä½œå“"""
        try:
            mix_id = None
            for pattern in [r'/collection/(\d+)', r'/mix/detail/(\d+)']:
                m = re.search(pattern, url)
                if m:
                    mix_id = m.group(1)
                    break
            if not mix_id:
                logger.error(f"æ— æ³•ä»åˆé›†é“¾æ¥æå–ID: {url}")
                return False
            await self._download_mix_by_id(mix_id)
            return True
        except Exception as e:
            logger.error(f"ä¸‹è½½åˆé›†å¤±è´¥: {e}")
            return False

    async def _download_mix_by_id(self, mix_id: str):
        """æŒ‰åˆé›†IDä¸‹è½½å…¨éƒ¨ä½œå“"""
        cursor = 0
        downloaded = 0

        console.print(f"\n[green]å¼€å§‹ä¸‹è½½åˆé›† {mix_id} ...[/green]")

        while True:
            await self.rate_limiter.acquire()
            data = await self._fetch_mix_awemes(mix_id, cursor)
            if not data:
                break

            aweme_list = data.get('aweme_list') or []
            if not aweme_list:
                break

            for aweme in aweme_list:
                success = await self._download_media_files(aweme)
                if success:
                    downloaded += 1

            if not data.get('has_more'):
                break
            cursor = data.get('cursor', 0)

        console.print(f"[green]âœ… åˆé›†ä¸‹è½½å®Œæˆï¼Œå…±ä¸‹è½½ {downloaded} ä¸ª[/green]")

    async def _fetch_mix_awemes(self, mix_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–åˆé›†ä¸‹ä½œå“åˆ—è¡¨"""
        try:
            params_list = [
                f'mix_id={mix_id}',
                f'cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true',
                'engine_name=Blink',
                'engine_version=122.0.0.0',
                'os_name=Mac',
                'os_version=10.15.7',
                'cpu_core_num=8',
                'device_memory=8',
                'platform=PC',
                'downlink=10',
                'effective_type=4g',
                'round_trip_time=50',
                f'msToken={self.mstoken}',
                f'device_id={self.device_id}',
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.USER_MIX
            try:
                x_bogus = get_x_bogus(params, self.headers.get('User-Agent'))
                full_url = f"{api_url}{params}&X-Bogus={x_bogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•åŸæœ‰æ–¹æ³•")
                try:
                    xbogus = self.utils.getXbogus(params)
                    full_url = f"{api_url}{params}&X-Bogus={xbogus}"
                except Exception as e2:
                    logger.warning(f"åŸæœ‰X-Bogusæ–¹æ³•ä¹Ÿå¤±è´¥: {e2}, ä½¿ç”¨æ— ç­¾å")
                    full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚åˆé›†ä½œå“åˆ—è¡¨: {full_url[:100]}...")

            # ç¡®ä¿headersåŒ…å«msToken
            headers = {**self.headers}
            if 'Cookie' in headers:
                if 'msToken=' not in headers['Cookie']:
                    headers['Cookie'] += f'; msToken={self.mstoken}'
            else:
                headers['Cookie'] = f'msToken={self.mstoken}'

            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None
                    data = json.loads(text)
                    # USER_MIX è¿”å›æ²¡æœ‰ç»Ÿä¸€çš„ status_codeï¼Œè¿™é‡Œç›´æ¥è¿”å›
                    return data
        except Exception as e:
            logger.error(f"è·å–åˆé›†ä½œå“å¤±è´¥: {e}")
        return None

    async def download_music(self, url: str) -> bool:
        """æ ¹æ®éŸ³ä¹é¡µé“¾æ¥ä¸‹è½½éŸ³ä¹ä¸‹çš„æ‰€æœ‰ä½œå“ï¼ˆæ”¯æŒå¢é‡ï¼‰"""
        try:
            # æå– music_id
            music_id = None
            m = re.search(r'/music/(\d+)', url)
            if m:
                music_id = m.group(1)
            if not music_id:
                logger.error(f"æ— æ³•ä»éŸ³ä¹é“¾æ¥æå–ID: {url}")
                return False

            cursor = 0
            downloaded = 0
            limit_num = 0
            try:
                limit_num = int((self.config.get('number', {}) or {}).get('music', 0))
            except Exception:
                limit_num = 0

            console.print(f"\n[green]å¼€å§‹ä¸‹è½½éŸ³ä¹ {music_id} ä¸‹çš„ä½œå“...[/green]")

            while True:
                await self.rate_limiter.acquire()
                data = await self._fetch_music_awemes(music_id, cursor)
                if not data:
                    break
                aweme_list = data.get('aweme_list') or []
                if not aweme_list:
                    break

                for aweme in aweme_list:
                    if limit_num > 0 and downloaded >= limit_num:
                        console.print(f"[yellow]å·²è¾¾åˆ°éŸ³ä¹ä¸‹è½½æ•°é‡é™åˆ¶: {limit_num}[/yellow]")
                        return True
                    if self._should_skip_increment('music', aweme, music_id=music_id):
                        continue
                    success = await self._download_media_files(aweme)
                    if success:
                        downloaded += 1
                        self._record_increment('music', aweme, music_id=music_id)

                if not data.get('has_more'):
                    break
                cursor = data.get('cursor', 0)

            console.print(f"[green]âœ… éŸ³ä¹ä½œå“ä¸‹è½½å®Œæˆï¼Œå…±ä¸‹è½½ {downloaded} ä¸ª[/green]")
            return True
        except Exception as e:
            logger.error(f"ä¸‹è½½éŸ³ä¹é¡µå¤±è´¥: {e}")
            return False

    async def _fetch_music_awemes(self, music_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–éŸ³ä¹ä¸‹ä½œå“åˆ—è¡¨"""
        try:
            params_list = [
                f'music_id={music_id}',
                f'cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true'
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.MUSIC
            try:
                xbogus = self.utils.getXbogus(params)
                full_url = f"{api_url}{params}&X-Bogus={xbogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•ä¸å¸¦X-Bogus")
                full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚éŸ³ä¹ä½œå“åˆ—è¡¨: {full_url[:100]}...")
            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=self.headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None
                    data = json.loads(text)
                    return data
        except Exception as e:
            logger.error(f"è·å–éŸ³ä¹ä½œå“å¤±è´¥: {e}")
        return None
    
    def _check_time_filter(self, aweme: Dict) -> bool:
        """æ£€æŸ¥æ—¶é—´è¿‡æ»¤"""
        start_time = self.config.get('start_time')
        end_time = self.config.get('end_time')
        
        if not start_time and not end_time:
            return True
        
        raw_create_time = aweme.get('create_time')
        if not raw_create_time:
            return True
        
        create_date = None
        if isinstance(raw_create_time, (int, float)):
            try:
                create_date = datetime.fromtimestamp(raw_create_time)
            except Exception:
                create_date = None
        elif isinstance(raw_create_time, str):
            for fmt in ('%Y-%m-%d %H.%M.%S', '%Y-%m-%d_%H-%M-%S', '%Y-%m-%d %H:%M:%S'):
                try:
                    create_date = datetime.strptime(raw_create_time, fmt)
                    break
                except Exception:
                    pass
        
        if create_date is None:
            return True
        
        if start_time:
            start_date = datetime.strptime(start_time, '%Y-%m-%d')
            if create_date < start_date:
                return False
        
        if end_time:
            end_date = datetime.strptime(end_time, '%Y-%m-%d')
            if create_date > end_date:
                return False
        
        return True
    
    async def run(self):
        """è¿è¡Œä¸‹è½½å™¨"""
        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        console.print(Panel.fit(
            "[bold cyan]æŠ–éŸ³ä¸‹è½½å™¨ v3.0 - ç»Ÿä¸€å¢å¼ºç‰ˆ[/bold cyan]\n"
            "[dim]æ”¯æŒè§†é¢‘ã€å›¾æ–‡ã€ç”¨æˆ·ä¸»é¡µã€åˆé›†æ‰¹é‡ä¸‹è½½[/dim]",
            border_style="cyan"
        ))

        # åˆå§‹åŒ–Cookieä¸è¯·æ±‚å¤´
        await self._initialize_cookies_and_headers()

        # è·å–URLåˆ—è¡¨
        urls = self.config.get('link', [])
        # å…¼å®¹ï¼šå•æ¡å­—ç¬¦ä¸²
        if isinstance(urls, str):
            urls = [urls]
        if not urls:
            console.print("[red]æ²¡æœ‰æ‰¾åˆ°è¦ä¸‹è½½çš„é“¾æ¥ï¼[/red]")
            return

        # åˆ†æURLç±»å‹
        console.print(f"\n[cyan]ğŸ“Š é“¾æ¥åˆ†æ[/cyan]")
        url_types = {}
        for url in urls:
            content_type = self.detect_content_type(url)
            url_types[url] = content_type
            console.print(f"  â€¢ {content_type.upper()}: {url[:50]}...")

        # å¼€å§‹ä¸‹è½½
        console.print(f"\n[bold green]â³ å¼€å§‹ä¸‹è½½ {len(urls)} ä¸ªé“¾æ¥[/bold green]\n")

        # ç®€åŒ–è¿›åº¦æ˜¾ç¤ºï¼Œé¿å…Progresså†²çª
        for i, url in enumerate(urls, 1):
            content_type = url_types[url]
            console.print(f"\n[{i}/{len(urls)}] å¤„ç†: {url}")

            if content_type == ContentType.VIDEO or content_type == ContentType.IMAGE:
                # ä¸ºå•ä¸ªè§†é¢‘/å›¾æ–‡åˆ›å»ºç‹¬ç«‹çš„Progress
                with Progress(
                    SpinnerColumn(),
                    TextColumn("[progress.description]{task.description}"),
                    BarColumn(bar_width=40),
                    TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                    console=console,
                    transient=True
                ) as progress:
                    task = progress.add_task("æ­£åœ¨ä¸‹è½½...", total=100)
                    await self.download_single_video(url, progress, task)

            elif content_type == ContentType.USER:
                await self.download_user_page(url)
            elif content_type == ContentType.MIX:
                await self.download_mix(url)
            elif content_type == ContentType.MUSIC:
                await self.download_music(url)
            else:
                console.print(f"[yellow]ä¸æ”¯æŒçš„å†…å®¹ç±»å‹: {content_type}[/yellow]")

            # æ˜¾ç¤ºè¿›åº¦
            console.print(f"[dim]è¿›åº¦: {i}/{len(urls)} | æˆåŠŸ: {self.stats.success} | å¤±è´¥: {self.stats.failed}[/dim]")

        # æ˜¾ç¤ºç»Ÿè®¡
        self._show_stats()
    
    def _show_stats(self):
        """æ˜¾ç¤ºä¸‹è½½ç»Ÿè®¡"""
        console.print("\n" + "=" * 60)
        
        # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
        table = Table(title="ğŸ“Š ä¸‹è½½ç»Ÿè®¡", show_header=True, header_style="bold magenta")
        table.add_column("é¡¹ç›®", style="cyan", width=12)
        table.add_column("æ•°å€¼", style="green")
        
        stats = self.stats.to_dict()
        table.add_row("æ€»ä»»åŠ¡æ•°", str(stats['total']))
        table.add_row("æˆåŠŸ", str(stats['success']))
        table.add_row("å¤±è´¥", str(stats['failed']))
        table.add_row("è·³è¿‡", str(stats['skipped']))
        table.add_row("æˆåŠŸç‡", stats['success_rate'])
        table.add_row("ç”¨æ—¶", stats['elapsed_time'])
        
        console.print(table)
        console.print("\n[bold green]âœ… ä¸‹è½½ä»»åŠ¡å®Œæˆï¼[/bold green]")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æŠ–éŸ³ä¸‹è½½å™¨ - ç»Ÿä¸€å¢å¼ºç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '-c', '--config',
        default='config_downloader.yml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config_downloader.yml)'
    )
    
    parser.add_argument(
        '-u', '--url',
        nargs='+',
        help='ç›´æ¥æŒ‡å®šè¦ä¸‹è½½çš„URL'
    )
    parser.add_argument(
        '-p', '--path',
        default=None,
        help='ä¿å­˜è·¯å¾„ (è¦†ç›–é…ç½®æ–‡ä»¶)'
    )
    parser.add_argument(
        '--auto-cookie',
        action='store_true',
        help='è‡ªåŠ¨è·å–Cookieï¼ˆéœ€è¦å·²å®‰è£…Playwrightï¼‰'
    )
    parser.add_argument(
        '--cookie',
        help='æ‰‹åŠ¨æŒ‡å®šCookieå­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "msToken=xxx; ttwid=yyy"'
    )
    
    args = parser.parse_args()
    
    # ç»„åˆé…ç½®æ¥æºï¼šä¼˜å…ˆå‘½ä»¤è¡Œ
    temp_config = {}
    if args.url:
        temp_config['link'] = args.url
    
    # è¦†ç›–ä¿å­˜è·¯å¾„
    if args.path:
        temp_config['path'] = args.path
    
    # Cookieé…ç½®
    if args.auto_cookie:
        temp_config['auto_cookie'] = True
        temp_config['cookies'] = 'auto'
    if args.cookie:
        temp_config['cookies'] = args.cookie
        temp_config['auto_cookie'] = False
    
    # å¦‚æœå­˜åœ¨ä¸´æ—¶é…ç½®ï¼Œåˆ™ç”Ÿæˆä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ä¾›ç°æœ‰æ„é€ å‡½æ•°ä½¿ç”¨
    if temp_config:
        # åˆå¹¶æ–‡ä»¶é…ç½®ï¼ˆå¦‚å­˜åœ¨ï¼‰
        file_config = {}
        if os.path.exists(args.config):
            try:
                with open(args.config, 'r', encoding='utf-8') as f:
                    file_config = yaml.safe_load(f) or {}
            except Exception:
                file_config = {}
        
        # å…¼å®¹ç®€åŒ–é”®å
        if 'links' in file_config and 'link' not in file_config:
            file_config['link'] = file_config['links']
        if 'output_dir' in file_config and 'path' not in file_config:
            file_config['path'] = file_config['output_dir']
        if 'cookie' in file_config and 'cookies' not in file_config:
            file_config['cookies'] = file_config['cookie']
        
        merged = {**(file_config or {}), **temp_config}
        with open('temp_config.yml', 'w', encoding='utf-8') as f:
            yaml.dump(merged, f, allow_unicode=True)
        config_path = 'temp_config.yml'
    else:
        config_path = args.config
    
    # è¿è¡Œä¸‹è½½å™¨
    downloader = None
    try:
        downloader = UnifiedDownloader(config_path)
        asyncio.run(downloader.run())
    except KeyboardInterrupt:
        console.print("\n[yellow]âš ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½[/yellow]")
    except Exception as e:
        console.print(f"\n[red]âŒ ç¨‹åºå¼‚å¸¸: {e}[/red]")
        logger.exception("ç¨‹åºå¼‚å¸¸")
    finally:
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡å¹¶ä¿å­˜æ—¥å¿—
        if downloader and hasattr(downloader, 'download_logger'):
            downloader.download_logger.finalize(time.time() - downloader.stats.start_time)

        # æ¸…ç†ä¸´æ—¶é…ç½®
        if args.url and os.path.exists('temp_config.yml'):
            os.remove('temp_config.yml')


if __name__ == '__main__':
    main()